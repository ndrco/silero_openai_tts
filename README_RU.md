# Silero TTS, совместимый с OpenAI API

**Локальный**, self-hosted сервер синтеза речи (Text-to-Speech, TTS), реализующий **OpenAI TTS API** (`POST /v1/audio/speech`).

Основная цель проекта — предоставить **backend TTS “вставил и работает”**, совместимый с OpenAI API, для
[OpenClaw](https://github.com/openclaw/openclaw) — чтобы OpenClaw мог говорить, не полагаясь на внешние облачные сервисы.
При этом этот сервер подходит **для любого** проекта, который ожидает OpenAI-совместимый TTS endpoint: достаточно указать
клиенту base URL этого сервера.

Под капотом используются модели **Silero TTS** через `torch.hub` (скачиваются при первом запуске), плюс небольшой пайплайн
нормализации текста, ориентированный на **русский и английский**, включая **раскрытие числительных**.

## Почему этот проект особенно полезен

Ключевое преимущество проекта — **очень быстрая озвучка на CPU**. На практике это позволяет оставить дефицитные
ресурсы GPU для локальной LLM, а TTS выполнять отдельно на CPU с низкой задержкой.

---

## Возможности

- **Совместимость с OpenAI API**: реализует `POST /v1/audio/speech` с привычными полями запроса:
  `model`, `input`, `voice`, `response_format`, `speed`.
- **Сделано для OpenClaw**, но работает с любым OpenAI-совместимым клиентом.
- **Поддержка русского и английского** (автоматическое распознавание).
- **Естественное чтение чисел**:
  - раскрывает целые числа в слова;
  - для русского языка согласует формы существительных с числами (например: “21 рубль / 22 рубля / 25 рублей”);
  - раскрывает частые шаблоны вроде `%` и `₽` (символ рубля).
- **Несколько голосов**:
  - принимает названия голосов OpenAI (`alloy`, `echo`, `fable`, `onyx`, `nova`, `shimmer`) и сопоставляет их со спикерами Silero;
  - также принимает напрямую идентификаторы спикеров Silero (например: `baya`, `aidar`, `kseniya`, `xenia`, `eugene`, `random`).
- **Несколько выходных форматов**: `wav`, `mp3`, `opus`, `aac`, `flac`.
- **Управление скоростью** (`0.25`–`4.0`) с помощью аудиофильтров FFmpeg.
- **Дисковый кэш**, чтобы не пересинтезировать одну и ту же фразу снова и снова.
- **Опциональный API key** (Bearer token) для приватных развёртываний.
- **По умолчанию работает на CPU**, с опциональной поддержкой GPU (CUDA), если ваша сборка PyTorch её поддерживает.

---

## Быстрый старт

### 1) Системные зависимости

Нужны **FFmpeg** (для кодирования и управления скоростью) и **libsndfile** (для ввода/вывода WAV).

**Debian / Ubuntu (включая WSL2):**
```bash
sudo apt update
sudo apt install -y ffmpeg libsndfile1
```

### 2) Python-окружение

```bash
python -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install -e .
```

### 3) Настройка

Скопируйте `.env.example` в `.env` и отредактируйте при необходимости:

```bash
cp .env.example .env
```

### 4) Запуск

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

Если проект установлен через `pip install -e .`, можно запускать через консольную команду:

```bash
silero-tts
```

Или вызывать её напрямую из виртуального окружения без активации:

```bash
./.venv/bin/silero-tts
```

При первом старте сервер скачает выбранную модель Silero (через `torch.hub`).

---

## API

### Endpoint

`POST /v1/audio/speech`

### Тело запроса (JSON)

| Поле | Тип | Обязательно | Примечания |
|------|------|-------------|------------|
| `model` | string | да | OpenAI-совместимое поле. Этим сервером **игнорируется** (оставлено для совместимости). |
| `input` | string | да | Текст для синтеза (типичный лимит: 1–4096 символов). |
| `voice` | string | да | Название голоса OpenAI или ID спикера Silero. |
| `response_format` | string | нет | `wav` (по умолчанию), `mp3`, `opus`, `aac`, `flac` |
| `speed` | number | нет | Скорость воспроизведения (по умолчанию `1.0`, диапазон `0.25`–`4.0`) |

### Пример (curl)

```bash
curl http://localhost:8000/v1/audio/speech   -H "Content-Type: application/json"   -d '{
    "model": "gpt-4o-mini-tts",
    "voice": "alloy",
    "input": "У меня 5 запросов и 21 рубль.",
    "response_format": "mp3",
    "speed": 1.1
  }'   --output out.mp3
```

### Аутентификация

Если `REQUIRE_AUTH=true`, добавьте:

```bash
-H "Authorization: Bearer YOUR_API_KEY"
```

---

## Интеграция с OpenClaw

OpenClaw ожидает OpenAI-совместимый TTS endpoint. Запустите этот сервер локально и настройте OpenClaw на:

- **Base URL**: `http://127.0.0.1:8000` (или адрес, где вы хостите сервер)
- **Endpoint**: `/v1/audio/speech`
- **API key**: опционально (только если вы включили `REQUIRE_AUTH`)

### Рекомендуемая конфигурация OpenClaw
Добавьте в конфиг OpenClaw (например, ~/.openclaw/openclaw.json) следующее:

**Обязательно** (чтобы OpenClaw отправлял запросы TTS в этот локальный сервер и не требовал реального ключа):

```json
"env": {
  "OPENAI_TTS_BASE_URL": "http://127.0.0.1:8000/v1",
  "OPENAI_API_KEY": "dummy-local-key"
}
```

- `OPENAI_TTS_BASE_URL` — базовый URL OpenAI-совместимого API (важно: с суффиксом `/v1`).
- `OPENAI_API_KEY` — “заглушка”: многим клиентам нужен какой-то ключ в конфиге даже для локального endpoint; если включите `REQUIRE_AUTH`, укажите здесь тот же токен, что и `API_KEY` на сервере.

**Желательно** (авто-озвучка + голос по умолчанию, при этом Edge TTS выключен):

```json
"messages": {
  "ackReactionScope": "group-mentions",
  "tts": {
    "provider": "openai",
    "auto": "always",
    "openai": { "voice": "alloy" },
    "edge": { "enabled": false }
  }
}
```

Результат: OpenClaw получает локальный синтез речи с меньшей задержкой и без внешних вызовов.

---

## Конфигурация

Конфигурация задаётся через переменные окружения (загружаются из `.env`).

### Сеть

- `HOST` (по умолчанию: `0.0.0.0`) — интерфейс, на котором слушать. Используйте `127.0.0.1`, чтобы ограничить доступ только локальной машиной.
- `PORT` (по умолчанию: `8000`) — порт, на котором слушать.

### Модель Silero

- `SILERO_LANGUAGE` (по умолчанию: `ru`) — код языка (например: `ru`, `en`).
- `SILERO_MODEL_ID` (по умолчанию: `v4_ru`) — ID модели Silero для выбранного языка (например: `v4_ru`, `v4_en`).
- `SILERO_SAMPLE_RATE` (по умолчанию: `48000`) — частота дискретизации на выходе в Гц (типичные значения: `8000`, `24000`, `48000`).
- `SILERO_DEVICE` (по умолчанию: `cpu`) — `cpu` или `cuda`.
- `SILERO_NUM_THREADS` (по умолчанию: `0`) — потоки инференса (`0` = авто).
- `SILERO_DEFAULT_SPEAKER` (по умолчанию: `baya`) — спикер, используемый когда `voice` неизвестен/не сопоставлен.
- `SILERO_MODELS_DIR` (по умолчанию: `models`) — каталог для скачанных моделей (если ваша реализация их сохраняет).

### Аутентификация

- `REQUIRE_AUTH` (по умолчанию: `false`) — если `true`, запросы должны включать `Authorization: Bearer ...`.
- `API_KEY` (по умолчанию: `dummy-local-key`) — ожидаемый Bearer token.

### Кэш

- `CACHE_DIR` (по умолчанию: `.cache_tts`) — каталог, где кэшируется сгенерированное аудио.
- `CACHE_MAX_FILES` (по умолчанию: `2000`) — максимальное количество файлов в кэше (при превышении удаляются самые старые).

### Кодирование аудио

- `FFMPEG_BIN` (по умолчанию: `ffmpeg`) — путь к бинарнику FFmpeg.

---

## Сопоставление голосов

Сервер принимает **названия голосов OpenAI** и сопоставляет их со спикерами Silero. Пример сопоставления:

| Голос OpenAI | Спикер Silero (пример) |
|---|---|
| `alloy` | `baya` |
| `echo` | `aidar` |
| `fable` | `kseniya` |
| `onyx` | `eugene` |
| `nova` | `xenia` |
| `shimmer` | `baya` |

Также можно передать спикера Silero напрямую (например: `aidar`, `baya`, `kseniya`, `xenia`, `eugene`, `random`).

---

## Нормализация текста (числа, валюты и т. п.)

Перед синтезом входной текст проходит через небольшой нормализатор, который:

- раскрывает целые числа (например: `5` → `five` / `пять`);
- раскрывает шаблоны вроде `10%` и `21 ₽`;
- в русском языке склоняет соседние существительные под число (более естественная грамматика).

Если нужны дополнительные правила (даты, время, сокращения), расширьте шаг нормализации.

---

## Устранение неполадок

- **Не получается вывести MP3/OPUS/AAC/FLAC**: убедитесь, что установлен `ffmpeg`, и `FFMPEG_BIN` указывает на него.
- **CUDA не используется**: проверьте, что ваша сборка PyTorch поддерживает CUDA, и `SILERO_DEVICE=cuda`.
- **Первый запуск медленный**: модель скачивается в первый раз. Последующие старты быстрее.
- **Нет звука / аудио повреждено**: сначала попробуйте `response_format: "wav"`, чтобы отделить проблемы кодирования.

---

## Лицензия

Проект распространяется под **лицензией MIT** (пермиссивная, “свободная” лицензия).
Сами модели Silero имеют свои условия лицензирования — пожалуйста, проверьте репозиторий Silero upstream для деталей.

---

## Благодарности

- [Silero Models](https://github.com/snakers4/silero-models) — TTS-модели, лежащие в основе.
- [OpenClaw](https://github.com/openclaw/openclaw) — проект чатбота, для поддержки которого был сделан этот сервер.
